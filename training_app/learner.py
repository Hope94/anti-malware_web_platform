import pandas as pd
from sklearn.model_selection import GridSearchCV,train_test_split
from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix
import numpy as np
import itertools
from sklearn.svm import LinearSVC
from sklearn.svm import SVC
from mlxtend.classifier import StackingClassifier
from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier,BaggingClassifier,AdaBoostClassifier, GradientBoostingClassifier
from sklearn.naive_bayes import GaussianNB,BernoulliNB
from sklearn.linear_model import LogisticRegression,SGDClassifier,PassiveAggressiveClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier



seed = 7
RANDOM_STATE = 42

N_JOBS = 1
PRE_DISPATCH = '2*n_jobs'

def init_classifier(n_samples):
    clf1 = KNeighborsClassifier(n_neighbors=1)
    clf2 = RandomForestClassifier(random_state=1)
    clf3 = LinearSVC()
    lr = LogisticRegression()

    return {
        'SVC': SVC(),
        'RandomForest': RandomForestClassifier(),
        'LinearSVC': LinearSVC(),
        'NaiveBays': BernoulliNB(),
        'SGD': SGDClassifier(),
        'PassiveAggressive': PassiveAggressiveClassifier(),
        'SAG': LogisticRegression(solver='sag', tol=1e-1, C=1.e4 / n_samples),
        'AdaBoost': AdaBoostClassifier(),
        'GBoosting':GradientBoostingClassifier(),
        'Bagging': BaggingClassifier(base_estimator=DecisionTreeClassifier(), random_state=seed),
        'Stacking' :  StackingClassifier(classifiers=[clf1, clf2, clf3], meta_classifier=lr,use_probas=True,
                          average_probas=False)
    }


def init_hyper_params (n_samples):
    svm_parameters = {'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],
                      'C': [1, 10, 100, 1000]}
    n_estimators_range  = np.arange(10, 100, 5)
    n_estimators_range_ = np.arange(10, 600, 10)
    randomForest_parameters = {"n_estimators": n_estimators_range,
                               'max_features': ['auto', 'sqrt', 'log2',None],
                               "max_depth": [3, None],
                               "bootstrap": [True, False],
                               "criterion": ["gini", "entropy"]}

    linear_svm_parameters = {'C': np.logspace(-5, 2, num=200)}

    alpha_range =10.0 ** -np.arange(1, 5)
    n =  np.ceil(10**6 /n_samples)

    sgd_parameters = {'loss': ['hinge', 'modified_huber', 'log', 'squared_hinge'],
                      'penalty': ['l1', 'l2', 'elasticnet'],
                      'average': [False, True],
                      'alpha': alpha_range,
                      'learning_rate': ['optimal', 'invscaling'],
                      'n_iter': [n],
                      'eta0': [0.01]
                      }
    adaboost_parameters = {'n_estimators': n_estimators_range_,
                           'learning_rate': [1.0, 0.1],
                           'algorithm': ['SAMME', 'SAMME.R'],
                           'random_state': seed}

    gboost_parameters = {'n_estimators' : n_estimators_range_,
                           'learning_rate':[1.0,0.1,0.01],
                           'max_features': ['auto', 'sqrt', 'log2',None],
                           'loss': ['deviance', 'exponential'],
                           'subsample': [1.0, 0.5],
                           'random_state': seed}

    bagging_parameters = { 'n_estimators':n_estimators_range,
                           'max_samples':1.0,
                           'max_features':1.0,
                           'bootstrap':[True,False],
                           'bootstrap_features':[False,True],
                           'oob_score':False}
    stacking_parameters = {'kneighborsclassifier__n_neighbors': [1, 5],
          'randomforestclassifier__n_estimators': [10, 50],
          'meta-logisticregression__C': [0.1, 10.0]}
    C_values = np.random.uniform(low=1e-10, high=10., size=100)
    passiveaggressive_parameters = {'C': C_values,
                                    'loss': ['hinge', 'squared_hinge'],
                                    'fit_intercept': [True, False],
                                    'random_state': seed}
    return {'SVC': svm_parameters,
                        'RandomForest': randomForest_parameters,
                        'LinearSVC': linear_svm_parameters,
                        'SGD': sgd_parameters,
            'PassiveAggressive':  passiveaggressive_parameters,
            'SAG': LogisticRegression(solver='sag', tol=1e-1, C=1.e4 / n_samples),
            'AdaBoost': adaboost_parameters,
            'GBoosting' : gboost_parameters,
            'Bagging': bagging_parameters,
            'Stacking': stacking_parameters
            }


scores = ['precision', 'recall','roc_auc']

def set_const_n_jobs(n_jobs: int):
    global  N_JOBS
    N_JOBS = n_jobs

def set_const_pre_dispatch(pre_dispatch):
    global PRE_DISPATCH
    PRE_DISPATCH = pre_dispatch




def train_hyper_parameters(estimator,X_train, y_train, nb_splits, param_grid,scorer):
    # use cross-validation to evaluate the performance of each parameter combination : grid search with cross-validation.
    clf = GridSearchCV(estimator=estimator, param_grid=param_grid, cv=nb_splits,
                               scoring= scorer,
                               n_jobs=1, pre_dispatch=PRE_DISPATCH
                                ,return_train_score=True)
    clf.fit(X_train, y_train)
    return {'best_params': clf.best_params_,
            'best_score': clf.best_score_,
            'best_estimator': clf.best_estimator_,
            'cv_results': pd.DataFrame(clf.cv_results_)}



def evaluate(estimator, X_test, y_test):
    try:
        auc = roc_auc_score(y_test, estimator.decision_function(X_test))
    except :
        auc = roc_auc_score(y_test,estimator.predict_proba(X_test)[:,1])
    conf_matrix = confusion_matrix(y_test, estimator.predict(X_test), labels=[0, 1])
    tn = conf_matrix[0, 0]
    tp = conf_matrix[1, 1]
    fp = conf_matrix[0, 1]
    fn = conf_matrix[1, 0]
    accuracy = (tp + tn) / (tp + tn + fp + fn)
    recall = tp / (tp + fn)
    precision = tp / (tp + fp)
    fpr = fp / (fp + tn)
    f1 = 2 * (precision * recall) / (precision + recall)
    return {
        'positives': tp + fn,
        'negatives': tn + fp,
        'auc': auc,
        'accuracy': accuracy,
        'recall': recall,
        'precision': precision,
        'f1': f1,
        'tp': tp,
        'tn': tn,
        'fp': fp,
        'fn': fn,
        'tpr': recall,
        'fpr': fpr
    }

import _pickle as pk
def save_object(obj, filename):
    with open(filename, 'wb') as output:  # Overwrites any existing file.
        pk.dump(obj, output)
def load_object(filename):
    with open(filename, 'rb') as output:
        return pk.load(output)

from main.vector_space_constractor.vectorizer import *
import time
if __name__ == '__main__':
    start = time.time()
    list_datasets = ['drebin', 'darwin', 'amd']
    print(list_datasets)
    list_types = ['defined_perm', 'activity', 'service', 'receiver', 'intent', 'component_count', 'hardware', 'provider', 'r_api_ps', 'used_permission_ps', 'r_api_ps_ax', 'url', 'suspicious_api']
    print(list_types)
    features_ids = get_datasets_features(datasets_name=list_datasets, type_features=list_types)
    print(features_ids)
    # features_ids = list(range(1,391592))
    # vc, cv = build_vector_space_dict(features_ids)
    # print(vc)
    # print('vc len ',len(vc))
    # X, y = get_X_y_datasets(vector_space_dict=vc, datasets=list_datasets, sparce=True, with_frequence=True)
    # print(X)
    # print(y)
    X = load_object( 'x.pkl')
    y =load_object( 'y.pkl')
    end = time.time()
    print(end - start)
    X_train, X_test, y_train, y_test = train_test_split(X, y,shuffle=True, random_state=RANDOM_STATE)
    # scaler = preprocessing.StandardScaler(with_mean=False).fit(X_train)
    # scaler.transform(X_test)
    n_samples = X_train.shape[0]
    hyper_params=init_hyper_params(n_samples)
    classifiers = init_classifier(n_samples)
    clf = 'RandomForest'
    grid_search_result = train_hyper_parameters(estimator=classifiers[clf],X_train=X_train,y_train=y_train,nb_splits=10,param_grid=hyper_params[clf],scorer='roc_auc')
    print(grid_search_result)
    estimator = grid_search_result['best_estimator']
    rv = evaluate(estimator, X_test, y_test)
    print(rv)
    end = time.time()
    print(end - start)
