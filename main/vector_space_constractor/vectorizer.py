from db_manager import get_apk_features, get_apks, get_apks_in_datasets
from django.db import transaction
import numpy as np
from scipy import sparse as sp
from sklearn.model_selection import train_test_split
from main.extractor.utils import RANDOM_STATE
import pandas as pd
import os

from sklearn import preprocessing
from db_manager import get_datasets_features,add_features_to_vs,insert_vector_space,get_apk_features_ids
from pfe_plateforme_web.settings import MEDIA_DIR

VS_DIR = os.path.join(MEDIA_DIR,'vc')

def build_vector_space_dict(features: list):
    f = [f.pk for f in features]
    _features = np.sort(f)
    _index = range(_features.size)
    return {feature: index for feature, index in zip(_features, _index)}, {index: feature for index, feature in
                                                                           zip(_index, _features)}

@transaction.atomic
def build_vector_space(dataset : list, type_feature : list,rep_type : str, scal : str):
    vs  =insert_vector_space(rep_type=rep_type,scal=scal)
    f = get_datasets_features(datasets_name=dataset, type_features=type_feature)
    add_features_to_vs(vs=vs,features=f)
    return vs,f


def get_apk_features_index(vector_space_dict: dict, apk_id: int) -> dict:
    """ get index of features that are present in the apk apk_id  """
    apk_features = get_apk_features_ids(apk_id)
    return {vector_space_dict[feature]: apk_features[feature]
            for feature in apk_features
            if feature in vector_space_dict}


def get_X_y(vector_space_dict: dict, apks: list, with_frequence = True,sparce=True):
    """ Create matrix X (indepandant variable) where rows represent apk in apks and columns represent features of vector_space_dict
    Ai,j=1 if feature j is present in apk i
    Create vector Y (dependant variable) where yj =1 if apk i is maligne """
    # apks = [(apk_id, malignity) ...], apk_id : int and malignity == 0 or 1
    nb_apks = len(apks)
    nb_dimensions = len(vector_space_dict)
    # create an empty LIL matrix X  n x m n:nombre d'apk , m: nombre de dimensions , type de donn√©e :int
    if sparce:
        X = sp.lil_matrix((nb_apks, nb_dimensions), dtype=np.int8)
    else:
        X = np.empty((nb_apks, nb_dimensions), dtype=np.int16)
    # create an array filled with zeros with shape = nb_apks and data type int
    y = np.zeros(nb_apks, dtype=np.int8)
    # create two lists : a list apk_ids of apk_id in apks and a list of apk malignities in apks
    apk_ids, apk_malignities = map(list, zip(*apks))
    # fill the matrix X and Y
    # for each Apk ( a row in matrix X )
    for row, apk_id, apk_malignity in zip(range(nb_apks), apk_ids, apk_malignities):
        # search for index of features that are present in apk
        features_indices = get_apk_features_index(vector_space_dict, apk_id)
        # X[i,j]=1 i=row ( the apk) j are index of features present in apk i
        if with_frequence:
            for idx in features_indices:
                X[row, idx] = features_indices[idx]
        else:
            X[row, np.sort(list(features_indices.keys()))] = 1
        if apk_malignity == 1:
            y[row] = 1
    if sparce:
        return X.tocsr(), y
    else:
        return X, y

# use this one
def get_X_y_datasets(vector_space_dict: dict, datasets: list,sparce=True, with_frequence = True):
    """ getX,y of apks in dataset datasets """
    apks = get_apks_in_datasets(datasets)
    return get_X_y(vector_space_dict=vector_space_dict, apks=apks,sparce=sparce,with_frequence=with_frequence)

def scale_X(X):
    scaler = preprocessing.RobustScaler()
    return scaler.fit_transform(X)

